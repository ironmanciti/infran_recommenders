{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SX9tp1pygVKg"
   },
   "outputs": [],
   "source": [
    "# TFRS와 호환되는 이전 version 설치\n",
    "!pip install -q tensorflow==2.15.0\n",
    "!pip install -q tensorflow-datasets==4.9.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "WkkrIefYZXvX",
    "outputId": "ca6b7597-7896-44f5-f58a-a74a6ae90e63"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.15.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensorflow version 확인\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z17OmgavQfp4"
   },
   "source": [
    "# 영화 추천 - 검색 모델\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6LC6y81Decc"
   },
   "source": [
    "실제 추천 시스템은 대개 두 단계로 구성됩니다:\n",
    "\n",
    "1. **검색 단계(Retrieval stage)**: 모든 가능한 후보군에서 초기 후보 수백 개 선택하는 역할을 합니다. 주요 목표는 사용자가 관심 없어 할 후보들을 효율적으로 걸러내는 것입니다. 검색 모델은 수백만 개의 후보와 다룰 수 있어야 하므로, 계산적으로 효율적이어야 합니다.\n",
    "\n",
    "2. **순위 단계(Ranking stage)**: 검색 모델의 출력 결과를 세밀하게 조정하여 가능한 최선의 추천 몇 가지를 선택합니다. 이 작업의 목표는 사용자가 관심 있을 법한 아이템 세트를 좁혀서 유력한 후보 목록을 작성하는 것입니다.\n",
    "\n",
    "이 노트북에서는 첫 번째 단계인 검색에 모델을 구현합니다.\n",
    "\n",
    "검색 모델은 두 개의 하위 모델로 구성됩니다:\n",
    "\n",
    "1. **쿼리 모델(Query model)**: 쿼리 feature를 사용하여 쿼리 표현(일반적으로 고정 차원의 임베딩 벡터)을 계산합니다.\n",
    "2. **후보 모델(Candidate model)**: 후보 feature를 사용하여 후보 표현(동일한 크기의 벡터)을 계산합니다.\n",
    "\n",
    "그런 다음 두 모델의 출력을 함께 곱하여 쿼리 후보 선호도 점수를 제공하며 점수가 높을수록 후보와 쿼리 간의 더 나은 일치를 나타냅니다.\n",
    "\n",
    "이 notebook에서는 Movielens 데이터 세트를 사용하여 이러한 two-tower  모델을 구축하고 훈련합니다.\n",
    "\n",
    "다음을 수행합니다:\n",
    "\n",
    "1. 데이터를 가져와서 훈련 세트와 테스트 세트로 나눕니다.\n",
    "2. 검색 모델을 구현합니다.\n",
    "3. 모델을 피팅하고 평가합니다.\n",
    "4. 효율적인 서빙을 위해 근사 최근접 이웃(ANN) 인덱스를 구축하여 모델을 내보냅니다.\n",
    "\n",
    "이러한 과정을 통해 사용자가 관심 있을 가능성이 높은 아이템을 효율적으로 검색하는 모델을 구축하고 평가하는 방법을 배울 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3xVkcgxlb6OO"
   },
   "outputs": [],
   "source": [
    "!pip install -q tensorflow-recommenders==0.7.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "SZGYDaF-m5wZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# 데이터를 보기 좋게 출력하기 위한 라이브러리\n",
    "import pprint\n",
    "# 임시 파일과 디렉토리를 생성하고 관리하기 위한 라이브러리\n",
    "import tempfile\n",
    "# 타입 힌트를 위한 라이브러리\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# 다양한 데이터셋을 쉽게 로드할 수 있는 라이브러리\n",
    "import tensorflow_datasets as tfds\n",
    "# 추천 시스템을 구축하기 위한 TensorFlow 라이브러리\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5PAqjR4a1RR4"
   },
   "source": [
    "## dataset 준비\n",
    "\n",
    "-  [Tensorflow Datasets](https://www.tensorflow.org/datasets)의 MovieLens 데이터셋을 사용합니다.  \n",
    "\n",
    "- movielens/100k_ratings를 로드하면 등급 데이터가 포함된 tf.data.Dataset 객체가 생성되고 movielens/100k_movies를 로드하면 영화 데이터만 포함하는 tf.data.Dataset 객체가 생성됩니다.\n",
    "\n",
    "- MovieLens 데이터 세트에는 미리 정의된 분할이 없기 때문에 모든 데이터는  `train` split 에 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aaQhqcLGP0jL",
    "outputId": "9f3665bb-a7d3-4fc1-bea2-60bb86c3ca4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 1682)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평점 데이터 로드\n",
    "# MovieLens 100k 데이터셋의 평점 데이터를 \"train\" 분할로 로드합니다.\n",
    "# \"train\" 분할은 모델이 충분히 학습할 수 있을 만큼의 데이터를 포함하고 있습니다.\n",
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "\n",
    "# 사용 가능한 모든 영화의 특성 로드\n",
    "# MovieLens 100k 데이터셋의 영화 특성 데이터를 \"train\" 분할로 로드합니다.\n",
    "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")\n",
    "\n",
    "# 평점 데이터와 영화 데이터의 길이를 출력합니다.\n",
    "len(ratings), len(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D7mLeuALHvQW",
    "outputId": "b0973ccd-6561-4538-eb9a-bce1dca37daa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': 45.0,\n",
      " 'movie_genres': array([7]),\n",
      " 'movie_id': b'357',\n",
      " 'movie_title': b\"One Flew Over the Cuckoo's Nest (1975)\",\n",
      " 'raw_user_age': 46.0,\n",
      " 'timestamp': 879024327,\n",
      " 'user_gender': True,\n",
      " 'user_id': b'138',\n",
      " 'user_occupation_label': 4,\n",
      " 'user_occupation_text': b'doctor',\n",
      " 'user_rating': 4.0,\n",
      " 'user_zip_code': b'53211'}\n"
     ]
    }
   ],
   "source": [
    "# ratings 데이터셋에서 1개의 샘플을 가져옵니다.\n",
    "for x in ratings.take(1).as_numpy_iterator():\n",
    "    # 가져온 샘플을 넘파이 형식으로 변환한 후 보기 좋게 출력합니다.\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bZRbZW8IH1YW",
    "outputId": "721ce9f2-637a-41e4-88be-bdbefb01efa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_genres': array([4]),\n",
      " 'movie_id': b'1681',\n",
      " 'movie_title': b'You So Crazy (1994)'}\n"
     ]
    }
   ],
   "source": [
    "# movies 데이터셋에서 1개의 샘플을 가져옵니다.\n",
    "for x in movies.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUdT-f4RxMKs"
   },
   "source": [
    "ratings 데이터세트에서 'user_id' 및 'movie_title' 필드만 사용합니다.  \n",
    "movies 데이터세트에서는 'movie_title' 필드만 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "uhbEvPJqxLec"
   },
   "outputs": [],
   "source": [
    "# ratings 데이터셋에서 \"movie_title\"과 \"user_id\" 열만 선택하여 새로운 데이터셋을 만듭니다.\n",
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "})\n",
    "\n",
    "# movies 데이터셋에서 \"movie_title\" 열만 추출하여 새로운 데이터셋을 만듭니다.\n",
    "movies = movies.map(lambda x: x[\"movie_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DG7ljNCBfEWX",
    "outputId": "9974dc10-6556-4d59-9409-70ee408555db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iu4XSa_G1nyN"
   },
   "source": [
    "## Train / Test split  \n",
    "\n",
    "그러나 여기서는 random 분할을 사용하여 ratings의 80%를 train 세트에 넣고 20%를 테스트 세트에 넣습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rS0eDfkjnjJL",
    "outputId": "7dab6409-17cd-4426-fdf3-f72a4aa1b1a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 20000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TensorFlow의 랜덤 시드를 설정하여 재현 가능한 결과를 만듭니다.\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# ratings 데이터셋을 섞습니다.\n",
    "# 총 100,000개의 데이터를 섞으며, 시드를 42로 설정하여 재현 가능한 결과를 보장합니다.\n",
    "# reshuffle_each_iteration=False로 설정하여 각 반복마다 데이터를 다시 섞지 않습니다.\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "# 섞인 데이터셋에서 처음 80,000개의 데이터를 훈련 데이터셋으로 사용합니다.\n",
    "train = shuffled.take(80_000)\n",
    "\n",
    "# 섞인 데이터셋에서 처음 80,000개의 데이터를 건너뛰고, 다음 20,000개의 데이터를 테스트 데이터셋으로 사용합니다.\n",
    "test = shuffled.skip(80_000).take(20_000)\n",
    "\n",
    "# 훈련 데이터셋과 테스트 데이터셋의 크기를 출력합니다.\n",
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GG9BOVMhLGVQ"
   },
   "source": [
    "또한 데이터에 존재하는 고유한 사용자 ID와 영화 제목을 알아봅시다.\n",
    "\n",
    "이는 범주형 특성의 원시 값을 모델의 임베딩 벡터에 매핑할 수 있어야 하기 때문에 중요합니다. 이를 위해서는 원시 특성 값을 연속 범위의 정수로 매핑하는 어휘가 필요합니다. 이를 통해 임베딩 테이블에서 해당 임베딩을 조회할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "qfHlf5UWPE58"
   },
   "outputs": [],
   "source": [
    "# 영화 제목 데이터 전체를 배치 처리합니다.\n",
    "movie_titles = movies.batch(10_000)\n",
    "# 사용자 ID 데이터 전체를 배치 처리하고, 각 배치에서 \"user_id\" 키에 해당하는 값을 매핑합니다.\n",
    "user_ids = ratings.batch(1_000_000).map(lambda x: x[\"user_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mnLvGZ89fibE",
    "outputId": "6135b668-6c42-4368-86cc-e7d2fe66c16d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=TensorSpec(shape=(None,), dtype=tf.string, name=None)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vOl71ahNK93R",
    "outputId": "c7704235-393c-4910-d79c-11c77ca59e5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b\"'Til There Was You (1997)\", b'1-900 (1994)',\n",
       "       b'101 Dalmatians (1996)', b'12 Angry Men (1957)', b'187 (1997)',\n",
       "       b'2 Days in the Valley (1996)',\n",
       "       b'20,000 Leagues Under the Sea (1954)',\n",
       "       b'2001: A Space Odyssey (1968)',\n",
       "       b'3 Ninjas: High Noon At Mega Mountain (1998)',\n",
       "       b'39 Steps, The (1935)'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복을 제거한 영화 제목 목록을 생성합니다.\n",
    "unique_movie_titles = np.unique(np.array(list(movie_titles)))\n",
    "# 중복을 제거한 사용자 ID 목록을 생성합니다.\n",
    "unique_user_ids = np.unique(np.array(list(user_ids)))\n",
    "\n",
    "# 중복 제거 영화 제목 목록에서 처음 10개를 출력합니다.\n",
    "unique_movie_titles[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCi-seR86qqa"
   },
   "source": [
    "## 모델 구현\n",
    "\n",
    "two-tower(Query model + Candidate model) 검색 모델을 구축합니다. 각 타워를 개별적으로 구축한 다음 최종 모델에서 결합합니다.\n",
    "\n",
    "- 이 모델의 주요 목적은 사용자가 관심이 없는 모든 후보 item을 효율적으로 제거하는 것입니다.   \n",
    "- 가능한 모든 후보 중 수백개의 초기 후보 집합을 선택하여 다음 단계의 순위 네트워크로 넘깁니다.  \n",
    "- 검색 모델은 수백만개의 후보 아이템을 처리할 수 있으므로 계산적으로 효율적이어야 합니다.  \n",
    "\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*9BVJU6t9XL_GLQU8D_4wGg.png\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z20PyfSXP3Um"
   },
   "source": [
    "### query tower\n",
    "\n",
    "쿼리 및 후보 표현(candidate representation)의 차원을 결정합니다. 더 큰 값을 주면 모델이 더 정확할 수 있지만 학습이 느리고 과적합되는 경향이 더 큽니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "QbIy1FP8aCTq"
   },
   "outputs": [],
   "source": [
    "# 사용자와 영화의 ID를 임베딩 벡터로 변환할 때 사용할 벡터의 차원을 32로 설정합니다.\n",
    "embedding_dimension = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJYwjpLRaEzj"
   },
   "source": [
    "쿼리 모델 자체를 정의 합니다.   Keras 전처리 레이어를 사용하여 먼저 사용자 ID를 정수로 변환한 다음`Embedding` 레이어를 통해 사용자 임베딩으로 변환합니다. 이전에 구한 사용자 ID 목록을 vocabulary로 사용합니다.  \n",
    "\n",
    "- StringLookup : string feature를 integer index로 mapping 하는 전처리 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "zLfFAloCKqMh"
   },
   "outputs": [],
   "source": [
    "# StringLookup 레이어를 사용하여 텍스트 데이터를 정수 인덱스로 변환하고,\n",
    "# 이어서 Embedding 레이어를 사용하여 각 정수 인덱스를 밀집 벡터로 매핑\n",
    "user_model = tf.keras.Sequential([\n",
    "  # 고유한 사용자 ID 목록에서 문자열을 조회\n",
    "  tf.keras.layers.StringLookup(vocabulary=unique_user_ids, mask_token=None),\n",
    "  # 정수 인덱스를 밀집 벡터로 매핑 (unkown token을 위한 추가 임베딩을 포함)\n",
    "  tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qvo2pEcdaiec"
   },
   "source": [
    "이와 같은 간단한 모델은 고전적인 행렬 분해 접근 방식과 정확히 일치합니다.  마지막에 embedding_dimension 전체 출력을 반환하는 한 표준 Keras 구성 요소를 사용하여 임의로 복잡한 모델로 쉽게 확장할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dG4YFy9SQ08d"
   },
   "source": [
    "### candidate tower\n",
    "\n",
    "동일한 작업을 candidate tower 에 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "kjn_lzzVSxrv"
   },
   "outputs": [],
   "source": [
    "# 영화 제목을 임베딩 벡터로 변환하는 모델\n",
    "movie_model = tf.keras.Sequential([\n",
    "  # 영화 제목을 고유한 정수 인덱스로 변환하는 문자열 조회 레이어\n",
    "  tf.keras.layers.StringLookup(vocabulary=unique_movie_titles, mask_token=None),\n",
    "  # 정수 인덱스를 고차원 임베딩 벡터로 변환하는 임베딩 레이어\n",
    "  # unknown token을 감안해 영화 제목의 수 + 1 만큼의 크기로 임베딩 레이어를 생성\n",
    "  tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkYTinZTT7f0"
   },
   "source": [
    "### Metrics\n",
    "\n",
    "훈련 데이터에는  positive (user, movie) 쌍이 있습니다. 우리 모델이 얼마나 좋은지 평가하려면, 모델이 계산하는 이 쌍의 선호도 점수를 다른 모든 가능한 후보들의 점수와 비교해야 합니다. 만약 positive 쌍에 대한 점수가 다른 후보들보다 높다면, 우리 모델은 매우 정확하다고 볼 수 있습니다.\n",
    "\n",
    "이를 위해 `tfrs.metrics.FactorizedTopK` 메트릭을 사용할 수 있습니다. 이 메트릭에는 필수 인자가 하나 있는데, 바로 평가를 위한 암시적 부정 후보들로 사용되는 데이터셋입니다.\n",
    "\n",
    "우리의 경우, 이것은 movies 데이터셋이며, 우리의 영화 모델을 통해 임베딩으로 변환됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "1dLDL6pZVPO8"
   },
   "outputs": [],
   "source": [
    "# 'movies' 데이터셋의 각 영화를 128개씩 묶어서 배치를 만들고, 'movie_model'을 이용해 영화의 임베딩을 계산합니다.\n",
    "# 계산된 임베딩들은 'FactorizedTopK' 메트릭의 후보로 사용되어 모델의 성능을 평가하는 데 사용됩니다.\n",
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "  candidates=movies.batch(128).map(movie_model)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCaCqJsXSkCo"
   },
   "source": [
    "### Loss\n",
    "\n",
    "다음 구성 요소는 모델을 훈련하는 데 사용되는 손실입니다. TFRS에는 이를 쉽게 하기 위한 여러 손실 계층과 task가 있습니다.\n",
    "\n",
    "이 경우 **손실 함수와 메트릭 계산**을 함께 묶는 편리한 래퍼인 'Retrieval' 작업 개체를 사용합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "tJ61Iz2QTBw3"
   },
   "outputs": [],
   "source": [
    "task = tfrs.tasks.Retrieval(metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-3xFC-1cbz0"
   },
   "source": [
    "task 자체는 쿼리 및 후보 임베딩을 인수로 사용하고 계산된 손실을 반환하는 Keras 계층입니다. 이를 사용하여 모델의 훈련 루프를 구현합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZUFeSlWRHGx"
   },
   "source": [
    "### The full model\n",
    "\n",
    "이제 모든 것을 하나의 모델로 통합할 수 있습니다. TFRS는 모델 구축을 간소화하는 기본 모델 클래스(`tfrs.models.Model`)를 노출합니다. 우리가 해야 할 일은 `__init__` 메소드에서 구성 요소를 설정하고 raw feature를 입력으로 받아 손실 값을 반환하는 `compute_loss` 메소드를 구현하는 것입니다.\n",
    "\n",
    "그러면 기본 모델이 우리 모델에 맞는 적절한 훈련 루프를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "gUDJG8rvVgNm"
   },
   "outputs": [],
   "source": [
    "# Movielens 데이터셋을 이용하여 사용자와 영화의 임베딩을 학습하는 추천 시스템 모델 정의\n",
    "class MovielensModel(tfrs.Model):\n",
    "\n",
    "  def __init__(self, user_model, movie_model):\n",
    "    super().__init__()\n",
    "    # movie_model과 user_model을 각각 Keras 모델로 초기화\n",
    "    self.movie_model: tf.keras.Model = movie_model\n",
    "    self.user_model: tf.keras.Model = user_model\n",
    "    # 추천 시스템의 학습과 평가를 위한 task를 초기화\n",
    "    self.task: tf.keras.layers.Layer = task\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    # 사용자 특성을 선택하고 user_model에 전달하여 임베딩을 계산\n",
    "    user_embeddings = self.user_model(features[\"user_id\"])\n",
    "    # 영화 특성을 선택하고 movie_model에 전달하여 임베딩을 계산\n",
    "    positive_movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
    "\n",
    "    # task는 손실(loss)과 메트릭(metrics)을 계산\n",
    "    return self.task(user_embeddings, positive_movie_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDN_LJGlnRGo"
   },
   "source": [
    "## Fitting and evaluating\n",
    "\n",
    "모델을 정의한 후 표준 Keras 피팅 및 평가 루틴을 사용하여 모델을 피팅하고 평가할 수 있습니다.\n",
    "\n",
    "먼저 모델을 인스턴스화하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "aW63YaqP2wCf"
   },
   "outputs": [],
   "source": [
    "# retrieval model 생성\n",
    "model = MovielensModel(user_model, movie_model)\n",
    "# 모델 컴파일 (Adagrad 옵티마이저를 사용하여 학습률을 0.1로 설정)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nma0vc2XdN5g"
   },
   "source": [
    "그런 다음 훈련 및 평가 데이터를 섞고 일괄 처리하고 캐시합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "53QJwY1gUnfv"
   },
   "outputs": [],
   "source": [
    "# 훈련 데이터셋을 섞고, 배치 크기를 8192로 설정한 후, 캐시 처리\n",
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "\n",
    "# 테스트 데이터셋의 배치 크기를 4096으로 설정한 후, 캐시 처리\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8mHTxKAdTJO"
   },
   "source": [
    "모델을 훈련합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZxPntlT8EFOZ",
    "outputId": "7c65b1c7-6f5b-4ba4-a427-45e4e791b9b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10/10 [==============================] - 15s 1s/step - factorized_top_k/top_1_categorical_accuracy: 1.0000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0016 - factorized_top_k/top_10_categorical_accuracy: 0.0049 - factorized_top_k/top_50_categorical_accuracy: 0.0487 - factorized_top_k/top_100_categorical_accuracy: 0.1125 - loss: 69817.7074 - regularization_loss: 0.0000e+00 - total_loss: 69817.7074\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 10s 1s/step - factorized_top_k/top_1_categorical_accuracy: 9.7500e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0122 - factorized_top_k/top_10_categorical_accuracy: 0.0263 - factorized_top_k/top_50_categorical_accuracy: 0.1404 - factorized_top_k/top_100_categorical_accuracy: 0.2617 - loss: 67498.8722 - regularization_loss: 0.0000e+00 - total_loss: 67498.8722\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 10s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0015 - factorized_top_k/top_5_categorical_accuracy: 0.0182 - factorized_top_k/top_10_categorical_accuracy: 0.0383 - factorized_top_k/top_50_categorical_accuracy: 0.1774 - factorized_top_k/top_100_categorical_accuracy: 0.3054 - loss: 66312.8984 - regularization_loss: 0.0000e+00 - total_loss: 66312.8984\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cached_train, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YsluR8audV9W"
   },
   "source": [
    "모델이 학습됨에 따라 손실이 감소하고 top-k 검색 메트릭 세트가 업데이트됩니다. 이는 전체 후보 집합에서 검색된 상위 k 항목에 true positive가 있는지 여부를 알려줍니다. 예를 들어 top-5 categorical accuracy정확도 메트릭이 0.2이면 평균적으로  true positive가 검색된 상위 5개 항목의 20%에 해당한다는 것을 알 수 있습니다.\n",
    "\n",
    "이 예에서는 평가뿐만 아니라 훈련 중에 메트릭을 평가합니다. 대규모 후보 집합에서는 이 작업이 매우 느릴 수 있으므로 훈련에서는 메트릭 계산을 끄고 평가에서만 실행하는 것이 현명할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W-zu6HLODNeI",
    "outputId": "bbe2a34e-ddd8-45d2-e7fa-5f0f5d96d76b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 5s 503ms/step - factorized_top_k/top_1_categorical_accuracy: 5.5000e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0093 - factorized_top_k/top_10_categorical_accuracy: 0.0229 - factorized_top_k/top_50_categorical_accuracy: 0.1191 - factorized_top_k/top_100_categorical_accuracy: 0.2347 - loss: 31083.5202 - regularization_loss: 0.0000e+00 - total_loss: 31083.5202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.0005499999970197678,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.00930000003427267,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.022949999198317528,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.11905000358819962,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.23465000092983246,\n",
       " 'loss': 28231.705078125,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 28231.705078125}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LB804xqpY_hP"
   },
   "source": [
    "테스트 세트의 성능이 훈련 세트의 성능보다 훨씬 나쁜 이유는 주로 두 가지 요인 때문입니다:\n",
    "\n",
    "1. **과적합(Overfitting)**: 모델이 훈련 데이터를 외우는 경향이 있기 때문에, 본 데이터에 대해 성능이 더 좋을 가능성이 높습니다. 이러한 과적합 현상은 모델이 많은 파라미터를 가질 때 특히 강하게 나타납니다. 모델 정규화 및 사용자 및 영화 특성의 사용을 통해 모델이 본 적 없는 데이터에 대해 더 잘 일반화할 수 있도록 하여 이를 완화할 수 있습니다.\n",
    "\n",
    "2. **이미 시청한 영화의 재추천**: 모델이 사용자가 이미 시청한 영화를 다시 추천하는 경우, 이러한 알려진 긍정적인 시청이 테스트 영화를 상위 K개 추천에서 밀어낼 수 있습니다. 이 두 번째 현상은 테스트 추천에서 이전에 본 영화를 제외함으로써 해결할 수 있습니다. 이 접근법은 추천 시스템 문헌에서 비교적 일반적이지만, 이 노트북에서는 고려하지 않습니다. 과거의 시청 이력과 맥락 정보로부터 모델이 자동으로 이러한 행동을 배울 것으로 예상하므로, 과거에 시청한 영화를 추천하지 않는 것이 중요하다면, 적절하게 지정된 모델이 이를 자동으로 학습할 것으로 기대해야 합니다. 추가적으로, 동일한 항목을 여러 번 추천하는 것(예: 언제나 인기 있는 TV 시리즈나 정기적으로 구매하는 상품)이 종종 적절할 수도 있습니다.\n",
    "\n",
    "요약하자면, 모델이 훈련 데이터에 과적합되어 테스트 데이터에 대한 성능이 떨어지는 현상과, 이미 시청한 영화를 다시 추천하는 것을 피하기 위한 전략에 대해 설명하고 있습니다. 모델이 과거 사용자의 행동과 맥락 정보를 바탕으로 스스로 학습하여 이러한 문제를 해결할 수 있도록 하는 것이 중요하며, 때로는 동일한 아이템을 여러 번 추천하는 것이 사용자에게 유용할 수 있음을 강조하고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NB2v43NJU3Xf"
   },
   "source": [
    "## 예측하기\n",
    "이제 모델이 있으므로 예측을 할 수 있습니다. 이를 위해 tfrs.layers.factorized_top_k.BruteForce 레이어를 사용할 수 있습니다.\n",
    "\n",
    "index.index_from_dataset 함수는 전체 영화 데이터 세트를 통해 영화 임베딩을 생성하고 이를 인덱스에 추가하여, 사용자 쿼리에 대한 영화 추천을 가능하게 하는 역할을 합니다. 이 함수는 주로 두 개의 파라미터를 받습니다.  하나는 후보 영화의 배치(batch), 다른 하나는 해당 영화를 임베딩으로 변환하는 모델입니다, 이 과정을 통해, 모델이 사용자 모델을 통해 생성된 쿼리 임베딩과 영화 모델을 통해 생성된 영화 임베딩 사이의 관계를 학습하고, 사용자에게 적합한 영화를 빠르게 검색하여 추천할 수 있습니다​​."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IRD6bEtZW_8j",
    "outputId": "794dbc3c-7380-4d20-feeb-149dfe1ff093"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 42에 대한 추천: [b\"Kid in King Arthur's Court, A (1995)\" b'Rudy (1993)'\n",
      " b'Homeward Bound: The Incredible Journey (1993)']\n"
     ]
    }
   ],
   "source": [
    "# 원시 쿼리 feature를 사용하고 전체 영화 데이터 세트에서 영화를 추천하는 모델을 생성\n",
    "brute_index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "# 영화 데이터셋을 묶어서 인덱스를 생성합니다. 여기서는 각 영화를 100개씩 배치로 처리하고,\n",
    "# 영화 모델을 매핑하여 영화 임베딩을 얻습니다.\n",
    "brute_index.index_from_dataset(\n",
    "  tf.data.Dataset.zip((movies.batch(100), movies.batch(100).map(model.movie_model)))\n",
    ")\n",
    "\n",
    "# 사용자 ID \"42\"에 대한 영화 추천을 실행합니다.\n",
    "_, titles = brute_index(tf.constant([\"42\"]))\n",
    "# 사용자 42에 대한 상위 3개 영화 추천을 출력합니다.\n",
    "print(f\"사용자 42에 대한 추천: {titles[0, :3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i0UFyyocksOF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
