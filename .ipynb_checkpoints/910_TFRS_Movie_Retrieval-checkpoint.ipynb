{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SX9tp1pygVKg"
   },
   "outputs": [],
   "source": [
    "!pip install -q tensorflow-recommenders\n",
    "!pip install -q --upgrade tensorflow-datasets\n",
    "!pip install -q scann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z17OmgavQfp4"
   },
   "source": [
    "# 영화 추천 - 검색 모델\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6LC6y81Decc"
   },
   "source": [
    "실제 추천 시스템은 대개 두 단계로 구성됩니다:\n",
    "\n",
    "1. **검색 단계(Retrieval stage)**: 모든 가능한 후보군에서 초기 후보 수백 개 선택하는 역할을 합니다. 주요 목표는 사용자가 관심 없어 할 후보들을 효율적으로 걸러내는 것입니다. 검색 모델은 수백만 개의 후보와 다룰 수 있어야 하므로, 계산적으로 효율적이어야 합니다.\n",
    "\n",
    "2. **순위 단계(Ranking stage)**: 검색 모델의 출력 결과를 세밀하게 조정하여 가능한 최선의 추천 몇 가지를 선택합니다. 이 작업의 목표는 사용자가 관심 있을 법한 아이템 세트를 좁혀서 유력한 후보 목록을 작성하는 것입니다.\n",
    "\n",
    "이 노트북에서는 첫 번째 단계인 검색에 모델을 구현합니다.\n",
    "\n",
    "검색 모델은 종종 두 개의 하위 모델로 구성됩니다:\n",
    "\n",
    "1. **쿼리 모델(Query model)**: 쿼리 feature를 사용하여 쿼리 표현(일반적으로 고정 차원의 임베딩 벡터)을 계산합니다.\n",
    "2. **후보 모델(Candidate model)**: 후보 feature를 사용하여 후보 표현(동일한 크기의 벡터)을 계산합니다.\n",
    "\n",
    "그런 다음 두 모델의 출력을 함께 곱하여 쿼리 후보 선호도 점수를 제공하며 점수가 높을수록 후보와 쿼리 간의 더 나은 일치를 나타냅니다.\n",
    "\n",
    "이 notebook에서는 Movielens 데이터 세트를 사용하여 이러한 two-tower  모델을 구축하고 훈련합니다.\n",
    "\n",
    "다음을 수행합니다:\n",
    "\n",
    "1. 데이터를 가져와서 훈련 세트와 테스트 세트로 나눕니다.\n",
    "2. 검색 모델을 구현합니다.\n",
    "3. 모델을 피팅하고 평가합니다.\n",
    "4. 효율적인 서빙을 위해 근사 최근접 이웃(ANN) 인덱스를 구축하여 모델을 내보냅니다.\n",
    "\n",
    "이러한 과정을 통해 사용자가 관심 있을 가능성이 높은 아이템을 효율적으로 검색하는 모델을 구축하고 평가하는 방법을 배울 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SZGYDaF-m5wZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5PAqjR4a1RR4"
   },
   "source": [
    "## dataset 준비\n",
    "\n",
    "-  [Tensorflow Datasets](https://www.tensorflow.org/datasets)의 MovieLens 데이터셋을 사용합니다.  \n",
    "\n",
    "- movielens/100k_ratings를 로드하면 등급 데이터가 포함된 tf.data.Dataset 객체가 생성되고 movielens/100k_movies를 로드하면 영화 데이터만 포함하는 tf.data.Dataset 객체가 생성됩니다.\n",
    "\n",
    "- MovieLens 데이터 세트에는 미리 정의된 분할이 없기 때문에 모든 데이터는  `train` split 에 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "aaQhqcLGP0jL"
   },
   "outputs": [],
   "source": [
    "# Ratings data.\n",
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "\n",
    "# Features of all the available movies.\n",
    "movies = tfds.load(\"movielens/100k-movies\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dpTwJhM6wf5g",
    "outputId": "c7ec46b1-d19f-46aa-da6b-ddfb30181fd7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 1682)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ratings), len(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D7mLeuALHvQW",
    "outputId": "9c41d16f-6a6a-4a43-bc80-35e0893046c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': 45.0,\n",
      " 'movie_genres': array([7]),\n",
      " 'movie_id': b'357',\n",
      " 'movie_title': b\"One Flew Over the Cuckoo's Nest (1975)\",\n",
      " 'raw_user_age': 46.0,\n",
      " 'timestamp': 879024327,\n",
      " 'user_gender': True,\n",
      " 'user_id': b'138',\n",
      " 'user_occupation_label': 4,\n",
      " 'user_occupation_text': b'doctor',\n",
      " 'user_rating': 4.0,\n",
      " 'user_zip_code': b'53211'}\n"
     ]
    }
   ],
   "source": [
    "for x in ratings.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bZRbZW8IH1YW",
    "outputId": "1dab43f8-6221-4716-bd31-2a589a94eef4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie_genres': array([4]),\n",
      " 'movie_id': b'1681',\n",
      " 'movie_title': b'You So Crazy (1994)'}\n"
     ]
    }
   ],
   "source": [
    "for x in movies.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUdT-f4RxMKs"
   },
   "source": [
    "ratings 데이터세트에서 'user_id' 및 'movie_title' 필드만 사용합니다.  \n",
    "movies 데이터세트에서는 'movie_title' 필드만 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "uhbEvPJqxLec"
   },
   "outputs": [],
   "source": [
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "})\n",
    "movies = movies.map(lambda x: x[\"movie_title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iu4XSa_G1nyN"
   },
   "source": [
    "## Train / Test split  \n",
    "\n",
    "그러나 여기서는 random 분할을 사용하여 ratings의 80%를 train 세트에 넣고 20%를 테스트 세트에 넣습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rS0eDfkjnjJL",
    "outputId": "ff5887b0-8dc0-4e3d-8c7a-24f5cd843e5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 20000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)\n",
    "\n",
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GG9BOVMhLGVQ"
   },
   "source": [
    "또한 데이터에 존재하는 고유한 사용자 ID와 영화 제목을 알아봅시다.\n",
    "\n",
    "이는 범주형 특성의 원시 값을 모델의 임베딩 벡터에 매핑할 수 있어야 하기 때문에 중요합니다. 이를 위해서는 원시 특성 값을 연속 범위의 정수로 매핑하는 어휘가 필요합니다. 이를 통해 임베딩 테이블에서 해당 임베딩을 조회할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qfHlf5UWPE58"
   },
   "outputs": [],
   "source": [
    "# 영화 제목 데이터 전체를 배치 처리합니다.\n",
    "movie_titles = movies.batch(10_000)\n",
    "# 사용자 ID 데이터 전체를 배치 처리하고, 각 배치에서 \"user_id\" 키에 해당하는 값을 매핑합니다.\n",
    "user_ids = ratings.batch(1_000_000).map(lambda x: x[\"user_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vOl71ahNK93R",
    "outputId": "cd53a482-ca0d-4296-fa1c-a97e8a966745"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b\"'Til There Was You (1997)\", b'1-900 (1994)',\n",
       "       b'101 Dalmatians (1996)', b'12 Angry Men (1957)', b'187 (1997)',\n",
       "       b'2 Days in the Valley (1996)',\n",
       "       b'20,000 Leagues Under the Sea (1954)',\n",
       "       b'2001: A Space Odyssey (1968)',\n",
       "       b'3 Ninjas: High Noon At Mega Mountain (1998)',\n",
       "       b'39 Steps, The (1935)'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복을 제거한 고유한 영화 제목 목록을 생성합니다.\n",
    "unique_movie_titles = np.unique(np.array(list(movie_titles)))\n",
    "# 중복을 제거한 고유한 사용자 ID 목록을 생성합니다.\n",
    "unique_user_ids = np.unique(np.array(list(user_ids)))\n",
    "\n",
    "# 고유한 영화 제목 목록에서 처음 10개를 출력합니다.\n",
    "unique_movie_titles[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCi-seR86qqa"
   },
   "source": [
    "## 모델 구현\n",
    "\n",
    "two-tower 검색 모델을 구축합니다. 각 타워를 개별적으로 구축한 다음 최종 모델에서 결합합니다.\n",
    "\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*9BVJU6t9XL_GLQU8D_4wGg.png\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z20PyfSXP3Um"
   },
   "source": [
    "### The query tower\n",
    "\n",
    "쿼리 및 후보 표현(candidate representation)의 차원을 결정합니다. 더 큰 값을 주면 모델이 더 정확할 수 있지만 학습이 느리고 과적합되는 경향이 더 큽니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "QbIy1FP8aCTq"
   },
   "outputs": [],
   "source": [
    "embedding_dimension = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJYwjpLRaEzj"
   },
   "source": [
    "쿼리 모델 자체를 정의 합니다.   Keras 전처리 레이어를 사용하여 먼저 사용자 ID를 정수로 변환한 다음`Embedding` 레이어를 통해 사용자 임베딩으로 변환합니다. 이전에 계산한 고유한 사용자 ID 목록을 vocabulary로 사용합니다.  \n",
    "\n",
    "- StringLookup : string feature를 integer index로 mapping 하는 전처리 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "zLfFAloCKqMh"
   },
   "outputs": [],
   "source": [
    "user_model = tf.keras.Sequential([\n",
    "  # 고유한 사용자 ID 목록에서 문자열을 조회합니다.\n",
    "  tf.keras.layers.StringLookup(vocabulary=unique_user_ids, mask_token=None),\n",
    "  # unkown token을 위한 추가 임베딩을 포함합니다.\n",
    "  tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qvo2pEcdaiec"
   },
   "source": [
    "이와 같은 간단한 모델은 고전적인 행렬 분해 접근 방식과 정확히 일치합니다.  마지막에 embedding_dimension 전체 출력을 반환하는 한 표준 Keras 구성 요소를 사용하여 임의로 복잡한 모델로 쉽게 확장할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dG4YFy9SQ08d"
   },
   "source": [
    "### The candidate tower\n",
    "\n",
    "동일한 작업을 candidate tower 에 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "kjn_lzzVSxrv"
   },
   "outputs": [],
   "source": [
    "movie_model = tf.keras.Sequential([\n",
    "  # 고유한 영화 제목 목록을 사용하여 문자열 조회를 수행합니다.\n",
    "  tf.keras.layers.StringLookup(vocabulary=unique_movie_titles, mask_token=None),\n",
    "  # unkown token을 감안해 영화 제목의 수 + 1 만큼의 크기로 임베딩 레이어를 생성합니다.\n",
    "  tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkYTinZTT7f0"
   },
   "source": [
    "### Metrics\n",
    "\n",
    "훈련 데이터에는  positive (user, movie) 쌍이 있습니다. 우리 모델이 얼마나 좋은지 평가하려면, 모델이 계산하는 이 쌍의 선호도 점수를 다른 모든 가능한 후보들의 점수와 비교해야 합니다. 만약 positive 쌍에 대한 점수가 다른 후보들보다 높다면, 우리 모델은 매우 정확하다고 볼 수 있습니다.\n",
    "\n",
    "이를 위해 `tfrs.metrics.FactorizedTopK` 메트릭을 사용할 수 있습니다. 이 메트릭에는 필수 인자가 하나 있는데, 바로 평가를 위한 암시적 부정 후보들로 사용되는 데이터셋입니다.\n",
    "\n",
    "우리의 경우, 이것은 movies 데이터셋이며, 우리의 영화 모델을 통해 임베딩으로 변환됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "1dLDL6pZVPO8"
   },
   "outputs": [],
   "source": [
    "# 'movies' 데이터셋의 각 영화를 128개씩 묶어서 배치를 만들고, 'movie_model'을 이용해 영화의 임베딩을 계산합니다.\n",
    "# 계산된 임베딩들은 'FactorizedTopK' 메트릭의 후보로 사용되어 모델의 성능을 평가하는 데 사용됩니다.\n",
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "  candidates=movies.batch(128).map(movie_model)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCaCqJsXSkCo"
   },
   "source": [
    "### Loss\n",
    "\n",
    "다음 구성 요소는 모델을 훈련하는 데 사용되는 손실입니다. TFRS에는 이를 쉽게 하기 위한 여러 손실 계층과 task가 있습니다.\n",
    "\n",
    "이 경우 **손실 함수와 메트릭 계산**을 함께 묶는 편리한 래퍼인 'Retrieval' 작업 개체를 사용합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "tJ61Iz2QTBw3"
   },
   "outputs": [],
   "source": [
    "task = tfrs.tasks.Retrieval(metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-3xFC-1cbz0"
   },
   "source": [
    "task 자체는 쿼리 및 후보 임베딩을 인수로 사용하고 계산된 손실을 반환하는 Keras 계층입니다. 이를 사용하여 모델의 훈련 루프를 구현합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZUFeSlWRHGx"
   },
   "source": [
    "### The full model\n",
    "\n",
    "이제 모든 것을 하나의 모델로 통합할 수 있습니다. TFRS는 모델 구축을 간소화하는 기본 모델 클래스(`tfrs.models.Model`)를 노출합니다. 우리가 해야 할 일은 `__init__` 메소드에서 구성 요소를 설정하고 raw feature를 입력으로 받아 손실 값을 반환하는 `compute_loss` 메소드를 구현하는 것입니다.\n",
    "\n",
    "그러면 기본 모델이 우리 모델에 맞는 적절한 훈련 루프를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "gUDJG8rvVgNm"
   },
   "outputs": [],
   "source": [
    "class MovielensModel(tfrs.Model):\n",
    "\n",
    "  def __init__(self, user_model, movie_model):\n",
    "    super().__init__()\n",
    "    # movie_model과 user_model을 각각 Keras 모델로 초기화합니다.\n",
    "    self.movie_model: tf.keras.Model = movie_model\n",
    "    self.user_model: tf.keras.Model = user_model\n",
    "    # 추천 시스템의 학습과 평가를 위한 task를 초기화합니다.\n",
    "    self.task: tf.keras.layers.Layer = task\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    # 사용자 특성을 선택하고 user_model에 전달하여 임베딩을 계산합니다.\n",
    "    user_embeddings = self.user_model(features[\"user_id\"])\n",
    "    # 영화 특성을 선택하고 movie_model에 전달하여 임베딩을 계산합니다.\n",
    "    positive_movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
    "\n",
    "    # task는 손실(loss)과 메트릭(metrics)을 계산합니다.\n",
    "    return self.task(user_embeddings, positive_movie_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDN_LJGlnRGo"
   },
   "source": [
    "## Fitting and evaluating\n",
    "\n",
    "모델을 정의한 후 표준 Keras 피팅 및 평가 루틴을 사용하여 모델을 피팅하고 평가할 수 있습니다.\n",
    "\n",
    "먼저 모델을 인스턴스화하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "aW63YaqP2wCf"
   },
   "outputs": [],
   "source": [
    "# retrieval model 생성\n",
    "model = MovielensModel(user_model, movie_model)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nma0vc2XdN5g"
   },
   "source": [
    "그런 다음 훈련 및 평가 데이터를 섞고 일괄 처리하고 캐시합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "53QJwY1gUnfv"
   },
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8mHTxKAdTJO"
   },
   "source": [
    "그런 다음 모델을 훈련합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZxPntlT8EFOZ",
    "outputId": "196ef691-6c95-469a-a98a-5a541eeac3a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10/10 [==============================] - 38s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0085 - factorized_top_k/top_10_categorical_accuracy: 0.0188 - factorized_top_k/top_50_categorical_accuracy: 0.0955 - factorized_top_k/top_100_categorical_accuracy: 0.1732 - loss: 69818.4688 - regularization_loss: 0.0000e+00 - total_loss: 69818.4688\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 28s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0029 - factorized_top_k/top_5_categorical_accuracy: 0.0190 - factorized_top_k/top_10_categorical_accuracy: 0.0383 - factorized_top_k/top_50_categorical_accuracy: 0.1645 - factorized_top_k/top_100_categorical_accuracy: 0.2881 - loss: 67478.2166 - regularization_loss: 0.0000e+00 - total_loss: 67478.2166\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 29s 3s/step - factorized_top_k/top_1_categorical_accuracy: 0.0032 - factorized_top_k/top_5_categorical_accuracy: 0.0225 - factorized_top_k/top_10_categorical_accuracy: 0.0452 - factorized_top_k/top_50_categorical_accuracy: 0.1861 - factorized_top_k/top_100_categorical_accuracy: 0.3123 - loss: 66292.5710 - regularization_loss: 0.0000e+00 - total_loss: 66292.5710\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(cached_train, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YsluR8audV9W"
   },
   "source": [
    "모델이 학습됨에 따라 손실이 감소하고 top-k 검색 메트릭 세트가 업데이트됩니다. 이는 전체 후보 집합에서 검색된 상위 k 항목에 true positive가 있는지 여부를 알려줍니다. 예를 들어 top-5 categorical accuracy정확도 메트릭이 0.2이면 평균적으로  true positive가 검색된 상위 5개 항목의 20%에 해당한다는 것을 알 수 있습니다.\n",
    "\n",
    "이 예에서는 평가뿐만 아니라 훈련 중에 메트릭을 평가합니다. 대규모 후보 집합에서는 이 작업이 매우 느릴 수 있으므로 훈련에서는 메트릭 계산을 끄고 평가에서만 실행하는 것이 현명할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W-zu6HLODNeI",
    "outputId": "e1157da0-d36a-4950-b2e5-5dbf95b863b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 10s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0010 - factorized_top_k/top_5_categorical_accuracy: 0.0093 - factorized_top_k/top_10_categorical_accuracy: 0.0213 - factorized_top_k/top_50_categorical_accuracy: 0.1211 - factorized_top_k/top_100_categorical_accuracy: 0.2295 - loss: 31076.3493 - regularization_loss: 0.0000e+00 - total_loss: 31076.3493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.0010499999625608325,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.009349999949336052,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.021250000223517418,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.12105000019073486,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.22945000231266022,\n",
       " 'loss': 28252.5859375,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 28252.5859375}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LB804xqpY_hP"
   },
   "source": [
    "테스트 세트의 성능이 훈련 세트의 성능보다 훨씬 나쁜 이유는 주로 두 가지 요인 때문입니다:\n",
    "\n",
    "1. **과적합(Overfitting)**: 모델이 훈련 데이터를 외우는 경향이 있기 때문에, 본 데이터에 대해 성능이 더 좋을 가능성이 높습니다. 이러한 과적합 현상은 모델이 많은 파라미터를 가질 때 특히 강하게 나타납니다. 모델 정규화 및 사용자 및 영화 특성의 사용을 통해 모델이 본 적 없는 데이터에 대해 더 잘 일반화할 수 있도록 하여 이를 완화할 수 있습니다.\n",
    "\n",
    "2. **이미 시청한 영화의 재추천**: 모델이 사용자가 이미 시청한 영화를 다시 추천하는 경우, 이러한 알려진 긍정적인 시청이 테스트 영화를 상위 K개 추천에서 밀어낼 수 있습니다. 이 두 번째 현상은 테스트 추천에서 이전에 본 영화를 제외함으로써 해결할 수 있습니다. 이 접근법은 추천 시스템 문헌에서 비교적 일반적이지만, 이 노트북에서는 고려하지 않습니다. 과거의 시청 이력과 맥락 정보로부터 모델이 자동으로 이러한 행동을 배울 것으로 예상하므로, 과거에 시청한 영화를 추천하지 않는 것이 중요하다면, 적절하게 지정된 모델이 이를 자동으로 학습할 것으로 기대해야 합니다. 추가적으로, 동일한 항목을 여러 번 추천하는 것(예: 언제나 인기 있는 TV 시리즈나 정기적으로 구매하는 상품)이 종종 적절할 수도 있습니다.\n",
    "\n",
    "요약하자면, 모델이 훈련 데이터에 과적합되어 테스트 데이터에 대한 성능이 떨어지는 현상과, 이미 시청한 영화를 다시 추천하는 것을 피하기 위한 전략에 대해 설명하고 있습니다. 모델이 과거 사용자의 행동과 맥락 정보를 바탕으로 스스로 학습하여 이러한 문제를 해결할 수 있도록 하는 것이 중요하며, 때로는 동일한 아이템을 여러 번 추천하는 것이 사용자에게 유용할 수 있음을 강조하고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NB2v43NJU3Xf"
   },
   "source": [
    "## 예측하기\n",
    "이제 모델이 있으므로 예측을 할 수 있습니다. 이를 위해 tfrs.layers.factorized_top_k.BruteForce 레이어를 사용할 수 있습니다.\n",
    "\n",
    "index.index_from_dataset 함수는 전체 영화 데이터 세트를 통해 영화 임베딩을 생성하고 이를 인덱스에 추가하여, 사용자 쿼리에 대한 영화 추천을 가능하게 하는 역할을 합니다. 이 함수는 주로 두 개의 파라미터를 받습니다.  하나는 후보 영화의 배치(batch), 다른 하나는 해당 영화를 임베딩으로 변환하는 모델입니다, 이 과정을 통해, 모델이 사용자 모델을 통해 생성된 쿼리 임베딩과 영화 모델을 통해 생성된 영화 임베딩 사이의 관계를 학습하고, 사용자에게 적합한 영화를 빠르게 검색하여 추천할 수 있습니다​​."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IRD6bEtZW_8j",
    "outputId": "ff3fe5d1-aa50-4feb-c626-5b151bee6887"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 42에 대한 추천: [b'Rudy (1993)' b'Homeward Bound: The Incredible Journey (1993)'\n",
      " b'Father of the Bride (1950)']\n"
     ]
    }
   ],
   "source": [
    "# 원시 쿼리 feature를 사용하고 전체 영화 데이터 세트에서 영화를 추천하는 모델을 생성합니다.\n",
    "brute_index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "# 영화 데이터셋을 묶어서 인덱스를 생성합니다. 여기서는 각 영화를 100개씩 배치로 처리하고,\n",
    "# 영화 모델을 매핑하여 영화 임베딩을 얻습니다.\n",
    "brute_index.index_from_dataset(\n",
    "  tf.data.Dataset.zip((movies.batch(100), movies.batch(100).map(model.movie_model)))\n",
    ")\n",
    "\n",
    "# 사용자 ID \"42\"에 대한 영화 추천을 실행합니다.\n",
    "_, titles = brute_index(tf.constant([\"42\"]))\n",
    "# 사용자 42에 대한 상위 3개 영화 추천을 출력합니다.\n",
    "print(f\"사용자 42에 대한 추천: {titles[0, :3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOoLv6ZMKg0L"
   },
   "source": [
    "물론 'BruteForce' 레이어는 모델이 많은 가능한 후보를 제공하기에는 너무 느릴 것입니다. 다음 섹션에서는 대략적인 검색 인덱스를 사용하여 속도를 높이는 방법을 보여줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFlvp5DK4Ow8"
   },
   "source": [
    "## Model serving\n",
    "\n",
    "two-tower 검색 모델에서 serving에는 두 가지 구성 요소가 있습니다.\n",
    "\n",
    "-  serving query mode. 쿼리의 feature를 가져와 쿼리 임베딩으로 변환\n",
    "\n",
    "- serving candidate model. 쿼리 모델에 의해 생성된 쿼리에 대한 응답으로 후보를 빠르게 대략적으로 조회할 수 있는 approximate nearest neighbours(ANN) 인덱스의 형태를 취합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nBBGodbE5ENC"
   },
   "source": [
    "예측 속도를 높이기 위해 대략적인 검색 인덱스(approximate retrieval index)를 내보낼 수도 있습니다. 이를 통해 수천만 명의 후보자로부터 권장 사항을 효율적으로 표시할 수 있습니다.\n",
    "\n",
    "그렇게 하기 위해 `scann` 패키지를 사용할 수 있습니다. 이것은 TFRS의 선택적 종속성이며 `!pip install -q scann`을 호출하여 별도로 설치했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rTz8yxyp5uwU",
    "outputId": "ea2f87dc-7719-4baf-dde2-d6699c381435"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 42에 대한 추천: [b'Rudy (1993)' b'Homeward Bound: The Incredible Journey (1993)'\n",
      " b'When a Man Loves a Woman (1994)']\n"
     ]
    }
   ],
   "source": [
    "scann_index = tfrs.layers.factorized_top_k.ScaNN(model.user_model)\n",
    "\n",
    "# ScaNN 레이어를 사용하여 사용자 모델을 기반으로 한 검색 인덱스를 생성\n",
    "scann_index.index_from_dataset(\n",
    "  tf.data.Dataset.zip((movies.batch(100), movies.batch(100).map(model.movie_model)))\n",
    ")\n",
    "\n",
    "# 추천\n",
    "_, titles = scann_index(tf.constant([\"42\"]))\n",
    "print(f\"사용자 42에 대한 추천: {titles[0, :3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpLnoUv256bS"
   },
   "source": [
    "이 레이어는 _approximate_ lookup을 수행합니다. 이렇게 하면 검색 정확도가 약간 떨어지지만 큰 후보 세트에서는 훨씬 더 빨라집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "i0UFyyocksOF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
